{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7054-12-300-l_drucker_se_su_st_st_512_32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert directory structure from synthnet evaluation pipeline format to Huggingface format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datasets import load_dataset\n",
    "# load a local dataset from image directory (huggingface)\n",
    "# https://huggingface.co/docs/datasets/image_dataset\n",
    "DATASET_TRAIN_NAME = 'visda2017'\n",
    "DS_TRAIN_DIR = f'/home/dritter/projects/evaluation-pipeline/data/{DATASET_TRAIN_NAME}/train/'\n",
    "OUT_ROOT_TRAIN = f'data/{DATASET_TRAIN_NAME}'\n",
    "# DS_TRAIN_DIR = f'/home/dennis/Desktop/work/evaluation_pipeline_data/visda/train/{DATASET_TRAIN_NAME}'\n",
    "# load the our data dir (evaluation pipeline format) \n",
    "# change directory structure \n",
    "#   from:   data/ds_name/images/class/mesh/images\n",
    "#   to:     data/ds_name/images/class/images\n",
    "for path, dns, fns in os.walk(DS_TRAIN_DIR):\n",
    "    for fn in fns:\n",
    "        split_path = path.split('/')\n",
    "        label = split_path[-2]\n",
    "        split = 'train'\n",
    "        os.makedirs(f'{OUT_ROOT_TRAIN}/{label}', exist_ok=True)\n",
    "        shutil.copy(f'{path}/{fn}', f'{OUT_ROOT_TRAIN}/{split}/{label}/{fn}')\n",
    "\n",
    "# load cifar10 (only small portion for demonstration purposes) \n",
    "# train_ds, test_ds = load_dataset('cifar10', split=['train[:5000]', 'test[:2000]'])\n",
    "# # split up training into training + validation\n",
    "# splits = train_ds.train_test_split(test_size=0.1)\n",
    "# train_ds = splits['train']\n",
    "# val_ds = splits['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bicycle', 'horse', 'car', 'person', 'motorcycle', 'truck', 'aeroplane', 'skateboard', 'train', 'plant', 'bus', 'knife']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datasets import load_dataset\n",
    "# load a local dataset from image directory (huggingface)\n",
    "# https://huggingface.co/docs/datasets/image_dataset\n",
    "DATASET_TEST_NAME = 'visda2017'\n",
    "DS_TRAIN_DIR = f'data/{DATASET_TRAIN_NAME}/train'\n",
    "DS_TEST_DIR = f'/home/dritter/projects/evaluation-pipeline/data/datasets/{DATASET_TEST_NAME}/val'\n",
    "OUT_ROOT_TEST = f'data/{DATASET_TEST_NAME}/val'\n",
    "\n",
    "# Get classes present in train dataset\n",
    "TRAIN_CLASSES = os.listdir('data/visda2017/train')\n",
    "print(TRAIN_CLASSES)\n",
    "\n",
    "for path, dns, fns in os.walk(DS_TEST_DIR):\n",
    "    for fn in fns:\n",
    "        split_path = path.split('/')\n",
    "        label = split_path[-1]\n",
    "        if label in TRAIN_CLASSES:\n",
    "            os.makedirs(f'{OUT_ROOT_TEST}/{label}', exist_ok=True)\n",
    "            shutil.copy(f'{path}/{fn}', f'{OUT_ROOT_TEST}/{label}/{fn}')\n",
    "\n",
    "# load cifar10 (only small portion for demonstration purposes) \n",
    "# train_ds, test_ds = load_dataset('cifar10', split=['train[:5000]', 'test[:2000]'])\n",
    "# # split up training into training + validation\n",
    "# splits = train_ds.train_test_split(test_size=0.1)\n",
    "# train_ds = splits['train']\n",
    "# val_ds = splits['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TRAIN_NAME = '7054-12-300-l_drucker_se_su_st_st_512_32'\n",
    "DATASET_TEST_NAME = 'topex-real-123_pb_256'\n",
    "TRAIN_CLASSES = os.listdir(f\"data/{DATASET_TRAIN_NAME}\")\n",
    "TEST_CLASSES = os.listdir(f\"data/{DATASET_TEST_NAME}\")\n",
    "\n",
    "for c in TEST_CLASSES:\n",
    "    if c not in TRAIN_CLASSES:\n",
    "        print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img_0', 'img_1', 'img_2', 'img_3', 'img_4', 'img_5', 'img_6', 'img_7', 'img_8', 'img_9', 'img_10', 'img_11', 'img_12', 'img_13', 'img_14', 'img_15', 'img_16', 'img_17', 'img_18', 'img_19', 'img_20', 'img_21', 'img_22', 'img_23', 'img_24', 'img_25', 'img_26', 'img_27', 'img_28', 'img_29', 'img_30', 'img_31', 'img_32', 'img_33', 'img_34', 'img_35', 'img_36', 'img_37', 'img_38', 'img_39', 'img_40', 'img_41', 'img_42', 'img_43', 'img_44', 'img_45', 'img_46', 'img_47', 'img_48', 'img_49', 'img_50', 'img_51', 'img_52', 'img_53', 'img_54', 'img_55', 'img_56', 'img_57', 'img_58', 'img_59', 'img_60', 'img_61', 'img_62', 'img_63', 'img_64', 'img_65', 'img_66', 'img_67', 'img_68', 'img_69', 'img_70', 'img_71', 'img_72', 'img_73', 'img_74', 'img_75', 'img_76', 'img_77', 'img_78', 'img_79', 'img_80', 'img_81', 'img_82', 'img_83', 'img_84', 'img_85', 'img_86', 'img_87', 'img_88', 'img_89', 'img_90', 'img_91', 'img_92', 'img_93', 'img_94', 'img_95', 'img_96', 'img_97', 'img_98', 'img_99']\n",
      "['label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'test_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3128/3583700309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0msss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'test_size'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "X = []\n",
    "y =[]\n",
    "for i in range(0,100):\n",
    "    X.append(f\"img_{i}\")\n",
    "    y.append(f\"label_{i%5}\")\n",
    "print(X)\n",
    "print(y)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "sss.get_n_splits(X, y)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN_i:\", train_index)\n",
    "    print(\"TEST_i:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "print(\"TRAIN\", (X_train, y_train))\n",
    "print(\"TEST\", (X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visda2017 test set (assign labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "data = 'data/visda2017/val'\n",
    "\n",
    "for path, dns, fns in os.walk(data):\n",
    "    for fn in fns:\n",
    "        fn_split = fn.split('_')\n",
    "        fn_split[1] = fn_split[1][:-4]\n",
    "        new_fn = '_'.join(fn_split)\n",
    "        shutil.move(f'{path}/{fn}', f'{path}/{new_fn}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('notebook')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc62b2d4b4d966ab9f1a1ca50fa77ca8df119ae3c427d80ca6d487cd9df480f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
