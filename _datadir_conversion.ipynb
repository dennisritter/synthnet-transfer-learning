{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7054-12-300-l_drucker_se_su_st_st_512_32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert directory structure from synthnet evaluation pipeline format to Huggingface format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datasets import load_dataset\n",
    "# load a local dataset from image directory (huggingface)\n",
    "# https://huggingface.co/docs/datasets/image_dataset\n",
    "DATASET_TRAIN_NAME = 'visda2017'\n",
    "DS_TRAIN_DIR = f'/home/dritter/projects/evaluation-pipeline/data/{DATASET_TRAIN_NAME}/train/'\n",
    "OUT_ROOT_TRAIN = f'data/{DATASET_TRAIN_NAME}'\n",
    "# DS_TRAIN_DIR = f'/home/dennis/Desktop/work/evaluation_pipeline_data/visda/train/{DATASET_TRAIN_NAME}'\n",
    "# load the our data dir (evaluation pipeline format) \n",
    "# change directory structure \n",
    "#   from:   data/ds_name/images/class/mesh/images\n",
    "#   to:     data/ds_name/images/class/images\n",
    "for path, dns, fns in os.walk(DS_TRAIN_DIR):\n",
    "    for fn in fns:\n",
    "        split_path = path.split('/')\n",
    "        label = split_path[-2]\n",
    "        split = 'train'\n",
    "        os.makedirs(f'{OUT_ROOT_TRAIN}/{label}', exist_ok=True)\n",
    "        shutil.copy(f'{path}/{fn}', f'{OUT_ROOT_TRAIN}/{split}/{label}/{fn}')\n",
    "\n",
    "# load cifar10 (only small portion for demonstration purposes) \n",
    "# train_ds, test_ds = load_dataset('cifar10', split=['train[:5000]', 'test[:2000]'])\n",
    "# # split up training into training + validation\n",
    "# splits = train_ds.train_test_split(test_size=0.1)\n",
    "# train_ds = splits['train']\n",
    "# val_ds = splits['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datasets import load_dataset\n",
    "# load a local dataset from image directory (huggingface)\n",
    "# https://huggingface.co/docs/datasets/image_dataset\n",
    "DATASET_TEST_NAME = 'visda2017'\n",
    "DS_TRAIN_DIR = f'data/{DATASET_TRAIN_NAME}/train'\n",
    "DS_TEST_DIR = f'/home/dritter/projects/evaluation-pipeline/data/datasets/{DATASET_TEST_NAME}/val'\n",
    "OUT_ROOT_TEST = f'data/{DATASET_TEST_NAME}/val'\n",
    "\n",
    "# Get classes present in train dataset\n",
    "TRAIN_CLASSES = os.listdir('data/visda2017/train')\n",
    "print(TRAIN_CLASSES)\n",
    "\n",
    "for path, dns, fns in os.walk(DS_TEST_DIR):\n",
    "    for fn in fns:\n",
    "        split_path = path.split('/')\n",
    "        label = split_path[-1]\n",
    "        if label in TRAIN_CLASSES:\n",
    "            os.makedirs(f'{OUT_ROOT_TEST}/{label}', exist_ok=True)\n",
    "            shutil.copy(f'{path}/{fn}', f'{OUT_ROOT_TEST}/{label}/{fn}')\n",
    "\n",
    "# load cifar10 (only small portion for demonstration purposes) \n",
    "# train_ds, test_ds = load_dataset('cifar10', split=['train[:5000]', 'test[:2000]'])\n",
    "# # split up training into training + validation\n",
    "# splits = train_ds.train_test_split(test_size=0.1)\n",
    "# train_ds = splits['train']\n",
    "# val_ds = splits['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TRAIN_NAME = '7054-12-300-l_drucker_se_su_st_st_512_32'\n",
    "DATASET_TEST_NAME = 'topex-real-123_pb_256'\n",
    "TRAIN_CLASSES = os.listdir(f\"data/{DATASET_TRAIN_NAME}\")\n",
    "TEST_CLASSES = os.listdir(f\"data/{DATASET_TEST_NAME}\")\n",
    "\n",
    "for c in TEST_CLASSES:\n",
    "    if c not in TRAIN_CLASSES:\n",
    "        print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "X = []\n",
    "y =[]\n",
    "for i in range(0,100):\n",
    "    X.append(f\"img_{i}\")\n",
    "    y.append(f\"label_{i%5}\")\n",
    "print(X)\n",
    "print(y)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "sss.get_n_splits(X, y)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN_i:\", train_index)\n",
    "    print(\"TEST_i:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "print(\"TRAIN\", (X_train, y_train))\n",
    "print(\"TEST\", (X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visda2017 test set (assign labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "data = 'data/visda2017/val'\n",
    "\n",
    "for path, dns, fns in os.walk(data):\n",
    "    for fn in fns:\n",
    "        fn_split = fn.split('_')\n",
    "        fn_split[1] = fn_split[1][:-4]\n",
    "        new_fn = '_'.join(fn_split)\n",
    "        shutil.move(f'{path}/{fn}', f'{path}/{new_fn}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('notebook')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc62b2d4b4d966ab9f1a1ca50fa77ca8df119ae3c427d80ca6d487cd9df480f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
